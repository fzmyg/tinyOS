# 内存管理

## 内存分页

### 分区原因

操作系统需要内存分页（memory paging）的主要原因是为了更有效地管理计算机的内存资源，提高系统的性能和稳定性。具体来说，内存分页有以下几个重要作用：

1. **内存超额分配：分页是实现虚拟内存系统的一种方式。在虚拟内存系统中，操作系统通过分页将程序的地址空间分为多个固定大小的页，这些页可以被独立地映射到物理内存中的任何位置。这允许**操作系统使得程序看似拥有比实际物理内存更多的内存空间**。
2. **不同进程间内存隔离**：分页机制有助于实现内存保护，确保不同的应用程序在内存中的数据不会互相干扰。每个进程都有自己独立的页表，这些页表将虚拟地址映射到物理地址，从而隔离了不同进程的内存空间。
3. **数据和代码共享**(**动态库**实现基础)：分页允许多个进程共享相同的物理内存页，如共享库和操作系统代码。这种共享减少了总体内存需求，提高了内存的利用率。
4. **减少内存碎片**：通过使用固定大小的页，分页简化了内存的分配和回收。操作系统可以轻松地分配、追踪和管理这些固定大小的内存块，**减少了内存碎片**的问题。
5. **内存效率提高**：分页可以动态地加载和卸载内存页，使操作系统能够根据需要将内存分配给不同的进程或者从不活跃的进程中回收内存。这种动态管理帮助操作系统更高效地使用有限的物理内存资源。

### 页表

现代操作系统多为4级页表，本操作系统为2级页表。

![](resource\内存管理\二级页表占用内存示意图.jpg)

#### 32位线性地址解析

![](resource\内存管理\32位线性地址解析.png)

- 高10位为**页目录表项索引**，用于在页目录表中查找页目录项，页目录中保存着页表的物理地址。
- 中10位为**页表项索引**，用于在页表中定位到页表项，页表项中保存着真实物理页地址。
- 低12为为**物理页内偏移**，和物理页地址相加得到真实的物理地址。

#### 64位线性地址解析

![](resource\内存管理\64位线性地址解析.png)

- 第48~63位为高位扩展位，通常用于地址的符号扩展，以支持操作系统的地址空间布局。
- 第39~47位P4为P4T表项索引，条目中保存着P3T物理地址。
- 第30~38位P3为P3T表项索引，条目中保存着P2T物理地址。
- 第21~29位P2为P2T表项索引，条目中保存着P1T物理地址。
- 第12~20位P1为P1T表项索引，条目中保存着物理页地址。
- 第0~11为页内偏移。

#### 页目录项及页表项

​																							页目录项及页表项各位示意图

<img src="resource\内存管理\页目录项及页表项示意图.jpg" style="zoom:50%;" />

##### 	页表/页目录表项低12位含义

- **P, Present，意为存在位** 。 若为 1 表示该页存在于物理内存中，若为 0 表示该表不在物理内存中 。 操 作系统的页式虚拟内存管理便是通过 P 位和相应的 PG(0x0e号中断)异常来实现的 。
- **RW, Read/Write，意为读写位** 。 若为 1 表示可读可写，若为 0 表示可读不可写 。
- **US, User/Supervisor，意为普通用户/超级用户位**。若为 1 时，表示处于 User级，任意级别( 0、1、 2、 3)特权的程序都可以访问该页 。 若为 0，表示处于 Supervisor 级，特权级别为 3 的程序不允许访问该页， 该页只允许特权级别为 0、1、 2 的程序可以访问。
- **PWT, Page-level Write-Through，意为页级通写位**，也称页级写透位 。 若为 1 表示此项采用通写方式， 表示该页不仅是普通内存，还是高速缓存。此项和高速缓存有关，“通写”是高速缓存的 一种工作方式， 本位用来间接决定是否用此方式改善该页的访问效率 。 这里咱们直接置为 0 就可以啦 。
- **PCD, Page-level Cache Disable，意为页级高速缓存禁止位**。 若为 1表示该页启用高速缓存，为 0表 示禁止将该页缓存 。 这里咱们将其置为 0。
- **A, Accessed，意为访问位** 。 若为 1 表示该页被 CPU 访问过啦，所以该位是由 CPU 设置的 。 还记得段描述符中的 A 位和 P 位吗?这两位在一起可以实现段式虚拟内存管理 。和它们一样，这里页目录项和页表 项中的 A 位也可以用来记录某一 内存页的使用频率(操作系统定期将该位清 0，统计一段时间内变成 1 的次 数)，从而当内存不足时，可以将使用频率较低的页面换出到外存(如硬盘)，同时将页目录项或页表项的 P 位置 0，下次访问该页引起 pagefault 异常时，中断处理程序将硬盘上的页再次换入，同时将 P 位置1.
- **D, Dirty，意为脏页位** 。当 CPU 对一个页面执行写操作时，就会设置对应页表项的 D 位为 l。 此项 仅针对页表项有效，并不会修改页目录项中的 D 位。
  PAT, Page Attribute Table，意为页属性表位，能够在页面一级的粒度上设置内存属性 。 比较复杂，将 此位置。即可 。
- **G,Global，意为全局位** 。 由于内存地址转换也是颇费周折，先得拆分虚拟地址，然后又要查页目录，又要 查页表的，所以为了提高获取物理地址的速度，将虚拟地址与物理地址转换结果存储在 TLB (Trnnslation Lookaside Buffer)中， TLB 以后咱们会细说。 在此先知道 TLB 是用来缓存地址转换结果的高速缓存就 ok啦。 此 G 位用来指定该页是否为全局页，为 1 表示是全局页，为 0 表示不是全局页 。 若为全局页，该页将在高速 缓存 TLB 中一直保存，给出虚拟地址直接就出物理地址啦，无需那三步骤转换。 由于 TLB 容量比较小 (一般 速度较快的存储设备容量都比较小)，所以这里面就存放使用频率较高的页面。 顺便说一句， 清空TLB有两种 方式， 一是用 invlpg指令针对单独虚拟地址条目清理，或者是重新加载 cr3 寄存器，这将直接清空 TLB。
- **AVL，意为 Available 位**，表示可用，谁可以用?当然是软件，操作系统可用该位， CPU 不理会该位 的值，那咱们也不理会吧 。

#### 启动分页

控制寄存器组中cr3用来存储页目录表的物理地址。cr0中最后1位为开启分页机制开关。

##### 代码实现

```asm
	PAGE_DIR_TABLE_ADDR equ 0x100000  ;1MB起始地址为页目录表起始地址
	
	mov eax,PAGE_DIR_TABLE_ADDR			
	mov cr3,eax			;加载页目录表起始地址到cr3		
	mov eax,cr0
	or  eax,0x80000000	;开启分页机制
	mov cr0,eax
```

## 位图

### 位图管理内存原因

1. **简单性和直观性**：位图的结构非常简单。在位图中，每一个比特（bit）代表内存中的一个块（block），通常是一个页（page）或一组连续的页。如果比特为0，表示相应的内存块是可用的；如果比特为1，则表示内存块正在使用中。这种方法直观且易于实现。
2. **空间效率**：尽管位图需要额外的内存来存储状态信息，但它相对节省空间，特别是在管理大量内存块时。与其他内存管理技术（如链表）相比，位图的空间开销通常更小。
3. **快速访问和修改**：位图允许操作系统快速检查内存块的状态（空闲或占用）。查找空闲内存块、分配和释放内存可以通过直接访问和修改位来迅速完成，这对于内存管理的效率至关重要。
4. **易于扩展和灵活性**：位图结构可以很容易地扩展以适应更多的内存块，只需增加更多的位即可。这种灵活性使得位图成为适应不同大小内存需求的有效工具。
5. **碎片管理**：通过使用位图，操作系统可以更容易地识别连续的空闲内存块，这有助于减少内存碎片。操作系统可以优先使用连续的空闲块，从而提高内存使用的效率。
6. **支持多种分配策略**：位图结构支持多种内存分配策略，如首次适配（first fit）、最佳适配（best fit）和最差适配（worst fit），操作系统可以根据具体需求选择最适合的策略。

### 数据结构定义

```c
struct Bitmap{
	uint32_t bitmap_byte_len;
	uint8_t * pbitmap;
};
```

### 位图操作API

```c
extern void initBitmap(Bitmap*bitmap); 					/*将位图清0*/
extern bool bitIsUsed(Bitmap*bitmap,uint32_t bit_index); /*检测位图指定bite位是否被使用*/
extern uint32_t scanBitmap(Bitmap*bitmap,uint32_t cnt); /*查找连续cnt位bite位未被使用的起始位，返回起始位*/
extern void setBitmap(Bitmap*bitmap,uint32_t bit_index,uint8_t value);/*设置位图中指定位的值*/
```

## 内存池

### 物理内存池

```c
struct pool{
        struct lock lock;   //内存池锁
        struct Bitmap bitmap;		//内存位图
        uint32_t m_start;   //内存起始位置
        uint32_t m_length;  //内存池管理长度
};
```

由于不同进程/线程进行系统调用都会修改物理内存池，因此需要中加锁保证原子操作。

设置内存起始位置和管理内存长度（上限4GB），内存位图的粒度为4KB（一页）。

### 虚拟内存池

```c
struct vmpool{
	struct Bitmap bitmap;     /*内存池位图*/
	uint32_t vm_start; /*虚拟内存起始内存*/
};
```

不同进程/线程有不同的虚拟内存池，不需加锁。

只需设置内存起始地址，虚拟地址范围无上限。

### 初始化物理内存池&内核虚拟内存池

```c
struct pool kernel_pool,user_pool; //定义内核物理池，用户物理池

//初始化内核和用户物理内存池，内核虚拟内存池
static void initAllPool(uint32_t all_mem)
{
	uint32_t used_mem = 0x100000 + PG_SIZE * 256 ; //1 pdt + 1 + 254
	uint32_t free_mem = all_mem - used_mem;
	ASSERT(free_mem > 0);
	uint32_t kernel_free_mem = free_mem / 2;
	uint32_t user_free_mem = free_mem - kernel_free_mem;
	uint32_t kernel_free_page = kernel_free_mem  / PG_SIZE;
	uint32_t user_free_page = user_free_mem / PG_SIZE;
	uint32_t kernel_bitmap_byte_len = kernel_free_page / 8;	
	uint32_t user_bitmap_byte_len = user_free_page / 8;	
	kernel_pool.bitmap.pbitmap = (void*)KERNEL_BITMAP_START;	
	user_pool.bitmap.pbitmap =(void*)( KERNEL_BITMAP_START + kernel_bitmap_byte_len);
	kernel_pool.bitmap.bitmap_byte_len = kernel_bitmap_byte_len;
	user_pool.bitmap.bitmap_byte_len = user_bitmap_byte_len;
	initBitmap(&kernel_pool.bitmap);
	initBitmap(&user_pool.bitmap);
	initLock(&kernel_pool.lock);	
	initLock(&user_pool.lock);
	kernel_pool.m_start = used_mem;
	kernel_pool.m_length = kernel_free_mem;
	user_pool.m_start = kernel_pool.m_start + kernel_pool.m_length;
	user_pool.m_length = user_free_mem;
	
	kernel_vmpool.bitmap.bitmap_byte_len = kernel_bitmap_byte_len;
	kernel_vmpool.bitmap.pbitmap = (void*)(KERNEL_BITMAP_START + kernel_bitmap_byte_len + user_bitmap_byte_len);
	kernel_vmpool.vm_start = KERNEL_HEAP_START;  //#define KERNEL_HEAP_START   0xc0100000
	initBitmap(&kernel_vmpool.bitmap);  
	
	put_str("[kernel bitmap start         ]:");put_int(KERNEL_BITMAP_START);put_char(10);
	put_str("[kernel bitmao end           ]:");put_int(KERNEL_BITMAP_START+kernel_pool.bitmap.bitmap_byte_len-1);put_char(10);
	put_str("[user bitmap start           ]:");put_int(KERNEL_BITMAP_START+kernel_pool.bitmap.bitmap_byte_len);put_char(10);
	put_str("[user bitmap end             ]:");put_int(KERNEL_BITMAP_START+kernel_pool.bitmap.bitmap_byte_len+user_pool.bitmap.bitmap_byte_len-1);put_char(10);
	put_str("[kernel virtual  bitmap start]:");put_int(KERNEL_BITMAP_START+kernel_pool.bitmap.bitmap_byte_len+user_pool.bitmap.bitmap_byte_len);put_char(10);
	put_str("[kernel virtual  bitmao end  ]:");put_int(KERNEL_BITMAP_START+kernel_pool.bitmap.bitmap_byte_len+user_pool.bitmap.bitmap_byte_len+kernel_vmpool.bitmap.bitmap_byte_len-1);put_char(10);
	
	put_str("[kernel physical memory start]:");put_int(kernel_pool.m_start);put_char(10);
	put_str("[kernel physical memory end  ]:");put_int(kernel_pool.m_start+kernel_pool.m_length-1);put_char(10);
	put_str("[user physical memory start  ]:");put_int(user_pool.m_start);put_char(10);
	put_str("[user physical memory end    ]:");put_int(user_pool.m_start+user_pool.m_length-1);put_char(10);
	put_str("[kernel virtual memory start ]:");put_int(kernel_vmpool.vm_start);put_char(10);
}
```

### 从内存池中申请内存

#### 从物理内存池中申请

```c
/* 从物理内存池中开辟内存，pf选择从用户还是内核物理池中开辟
 * 成功返回物理地址，失败返回空*/
static void* palloc(enum pool_flags pf,uint32_t pg_cnt)
{
	struct pool * pp = (pf==PF_KERNEL?&kernel_pool:&user_pool);
	acquireLock(&pp->lock);
	int bit_index = (int)scanBitmap(&pp->bitmap,pg_cnt);
	if(bit_index  == -1)
		return NULL;
	uint32_t cnt = pg_cnt;
        while(cnt >0) {setBitmap(&pp->bitmap,bit_index+cnt-1,1);cnt--;}
	releaseLock(&pp->lock);
	return (void*)(pp->m_start+bit_index*PG_SIZE);
}
```

#### 从虚拟内存池中申请

```c
/*从虚拟内存池中开辟虚拟内存
 *成功返虚拟地址，失败返回空*/
static void* valloc(struct vmpool *pp,uint32_t pg_cnt)
{
        int bit_index = (int)scanBitmap(&pp->bitmap,pg_cnt);
        if(bit_index  == -1)
                return NULL;
        uint32_t cnt = pg_cnt;
        while(cnt >0) {setBitmap(&pp->bitmap,bit_index+cnt-1,1);cnt--;}
        return (void*)(pp->vm_start+bit_index*PG_SIZE);
}
```

### 建立虚拟页到物理页的映射关系

#### 虚拟地址转换

##### 解析线性地址宏

```c
#define PDE_INDEX(ADDR) ((ADDR & 0xffc00000)>>22)  //获取pde索引
#define PTE_INDEX(ADDR) ((ADDR & 0x003ff000)>>12)  //获取pte索引
```

##### 获取指向pde&pte物理地址的虚拟地址

```c
//获取pde地址
uint32_t * getPdePtr(uint32_t vaddr)
{
	return (uint32_t*)(0xfffff000+PDE_INDEX(vaddr)*4); 
}

//获取pte地址
uint32_t * getPtePtr(uint32_t vaddr)
{
	return (uint32_t*)(0xffc00000 + (PDE_INDEX(vaddr)<<12) + PTE_INDEX(vaddr)*4);
}
```

#### 映射函数

```c
/* 映射虚拟地址到物理地址 （单位：页）*/
static void mapVaddr2Paddr(void*_vaddr,void* _paddr)
{
	uint32_t vaddr = (uint32_t)_vaddr , paddr = (uint32_t)_paddr;
	uint32_t * pde_ptr = getPdePtr((uint32_t)vaddr);
	uint32_t * pte_ptr = getPtePtr((uint32_t)vaddr);
	if((*pde_ptr & PG_P_1) == 0){ /*页表不存在*/
		void* page_table_paddr = palloc(PF_KERNEL,1);/*从内核物理池给页表申请物理地址*/
		*pde_ptr = ((uint32_t)page_table_paddr | PG_US_U | PG_RW_W | PG_P_1);/*设置页目录项为页表起始物理地址*/ 
		memset((void*)((uint32_t)pte_ptr&0xfffff000/*pte_ptr不一定是页表首项,因此需&0xfffff000*/),0,PG_SIZE);//初始化新申请的页表
		*pte_ptr = ((paddr & 0xfffff000) | PG_US_U | PG_RW_W | PG_P_1);/*将页表项设为要映射的物理地址*/
	}else{
		ASSERT((*pte_ptr & PG_P_1) == 0);
		*pte_ptr = ((paddr & 0xfffff000) | PG_US_U | PG_RW_W | PG_P_1);/*页表存在则直接映射*/
	}
}
```

### 取消虚拟页到物理页的映射

#### 清除物理内存池

```c
static void pfree(uint32_t pg_phy_addr)
{
	struct pool* mem_pool = (pg_phy_addr>=user_pool.m_start)?&user_pool:&kernel_pool;/*靠pg_phy_addr判断操作内存池对象是用户物理内存池还是内核物理内存池*/
	uint32_t bit_index = (pg_phy_addr-mem_pool->m_start)/PG_SIZE;
	acquireLock(&mem_pool->lock);
	setBitmap(&mem_pool->bitmap,bit_index,0);
	releaseLock(&mem_pool->lock);
}
```



#### 清除虚拟内存池

```c
/*将虚拟地址池置相应位0*/
static void vfree(enum pool_flags pf,void*_vaddr,uint32_t pg_cnt)
{
	struct task_struct* pcb =getpcb();
	struct vmpool * vmem_pool = (pf == PF_KERNEL)?&kernel_vmpool:&pcb->vaddr_pool; /*靠pf确定虚拟内存池操作对象是内核虚拟池还是用户PCB中虚拟池*/ 
	uint32_t bit_index = ((uint32_t)_vaddr-vmem_pool->vm_start)/PG_SIZE;
	uint32_t i = 0 ;
	for(i=0;i<pg_cnt;i++){
		setBitmap(&vmem_pool->bitmap,bit_index+i,0);
	}
}
```

#### 取消虚拟内存与物理内存映射

```c
/*修改页表删除虚拟内存到物理内存映射关系*/
static void unMapVaddr(uint32_t vaddr)
{
	uint32_t* pte_ptr = getPtePtr(vaddr);
	(*pte_ptr) &= (~PG_P_1); 			/*pte P位置0表示相应页不存在*/
	asm volatile ("invlpg %0"::"m"(vaddr):"memory"); /*更新页表缓存*/
}
```



### 申请内存接口函数

```c
/*
 * 申请内存  若pf==PF_KERNEL则在内核虚拟池申请虚拟地址并在内核物理池申请物理地址
 *          若pf==PF_USER 则在当前PCB中虚拟池申请虚拟地址并在用户物理池申请物理地址 
 * 虚拟地址连续而物理地址可不连续
 */
void* mallocPage(enum pool_flags pf,uint32_t pg_cnt)
{
	void*vmaddr_start = NULL;
	if(pf==PF_KERNEL){
		vmaddr_start = valloc(&kernel_vmpool,pg_cnt);  //pf==PF_KERNEL则在内核虚拟池申请虚拟地址
	}else{
		struct task_struct* pcb = getpcb();
		vmaddr_start = valloc(&pcb->vaddr_pool,pg_cnt);//pf==PF_USER 则在当前PCB虚拟池申请虚拟地址 
	}
	if(vmaddr_start == NULL) return NULL;	
	uint32_t count = 0;
	while(count++ < pg_cnt){
		void* phyaddr_start=palloc(pf,1);
		if(phyaddr_start == NULL) return NULL;
		mapVaddr2Paddr((void*)((uint32_t)vmaddr_start+(count-1)*PG_SIZE),(void*)phyaddr_start);
	}	
	return vmaddr_start;
}
```

```c
/*
 *  指定虚拟地址申请一页内存
 */
void* mallocOnePageByVaddr(enum pool_flags pf,void* vaddr)
{
	uint32_t v_addr = (uint32_t )vaddr;
	struct task_struct*pcb  = getpcb();
	struct vmpool* pvp = (pf==PF_KERNEL&&pcb->pgdir_vaddr==NULL)?&kernel_vmpool:&pcb->vaddr_pool;
	uint32_t bit_index = (v_addr - pvp->vm_start)/PG_SIZE;
	if(bitIsUsed(&pvp->bitmap,bit_index)){ 
		return NULL;
	}
	setBitmap(&pvp->bitmap,bit_index,1); 
	void*paddr=palloc(pf,1);
	mapVaddr2Paddr(vaddr,paddr);
	return vaddr;
}
```



### 释放内存接口函数

```c
/*内存释放总函数 1.物理位图置0，2.删除页映射，3.虚拟位图置0*/
static void mfree(enum pool_flags pf,void*_vaddr,uint32_t pg_cnt)
{
	uint32_t vaddr = (uint32_t)_vaddr,i=0;

	for(i=0;i<pg_cnt;i++){
		uint32_t paddr = (uint32_t)addr_v2p((void*)vaddr);
		pfree(paddr);         /*从物理内存池置0*/
		unMapVaddr(vaddr);    /* 页表项P位置0*/
		vaddr+= PG_SIZE;
	}
	vfree(pf,_vaddr,pg_cnt);  /*虚拟内存池置0*/
}
```



## 内存描述符

### 数据结构定义

```c
/*内存块描述符*/
struct mem_block_desc{
	struct list free_list;   	/*可用的mem_block组成的链表*/
	uint32_t block_size;        /*内存块大小*/
	uint32_t blocks_per_arena;  /*每个arena可存放mem_block数量*/
};

/* 申请内存4KB起始数据结构*/
struct arena{
	struct mem_block_desc* desc; //指向pcb中desc
	uint32_t cnt; 				 //large 为0，为*空闲*内存块数量，large为1，为总申请页数量
	bool large;  				 //为true表示以页为单位分配，为false表示以块为单位分配
};

/*内存块*/
struct mem_block{
	struct list_elem free_elem; /*内存块链表结点，用于组织块大小相同的内存块*/
};
```

- 其中arena位于每次申请的起始页的开头，记录申请内存的类型，若为大页申请(size>1024)，则cnt表示申请页的数量，否则，cnt表示1页中剩余空闲块数量。
- mem_block位于页中，被mem_block_desc中free_list串联起来。
- mem_block_desc位于每个进程的PCB中，每个进程都有自己的内存空间。

### 初始化内存块描述符数组

```c
/*初始化内存管理符*/
void initMemBlockDesc(struct mem_block_desc*descs)
{
	//内存块大小依次为 16 32 64 128 256 512 1024
	uint32_t size = 16;
	uint32_t desc_index = 0;
	for(;desc_index<MEM_DESC_CNT;desc_index++){
		list_init(&descs[desc_index].free_list); 
		descs[desc_index].block_size=size;
		descs[desc_index].blocks_per_arena = (PG_SIZE-sizeof(struct arena))/size;
		size*=2;
	}
}
```

### sys_malloc

malloc系统调用陷入函数

```c
/*内核态申请内存 
 *1.根据调用者选择内存池和pf位 ----> 2.通过mallocPage(pf,size)申请内存 
 *----> 判断为大块内存 ----> 直接返回内存--- end
 *|----> 判断为小块内存 ----> 寻找相应内存块描述符 ----> 若内存块描述符容量为空 ----> 通过arena->desc->free_list 串连起内存块(mem_block) ----> 返  *回首个mem_block
 *										  |----> 若内存块描述符容量不空 ----> 返回首个mem_block
 */
void * sys_malloc(uint32_t size)
{
	enum pool_flags pf=PF_USER;
	struct pool* mem_pool = NULL; 			
	uint32_t pool_size = 0; 	  			
	struct mem_block_desc*descs = NULL; 	
	struct task_struct*  cur_pcb = getpcb();
	/*根据调用者初始化参数*/
	if(cur_pcb->pgdir_vaddr == NULL){ 		
		pf = PF_KERNEL;
		pool_size = kernel_pool.m_length;
		mem_pool = & kernel_pool;
		descs = k_mem_block_descs;
	}else{	
		pf = PF_USER;
		pool_size = user_pool.m_length;
		mem_pool= &user_pool;
		descs = cur_pcb->descs;
	}

	if((size>0&&size<pool_size)== false){ //申请内存量超出内存池大小
		return NULL;                      //直接返回空
	}
	struct arena* arena=NULL;		  //申请内存起始地址
	if(size>1024){ /*申请内存数大于1024B*/
		uint32_t page_cnt = DIV_ROUND_UP(size+sizeof(struct arena),PG_SIZE); //申请PG_SIZE整数被内存
		arena = mallocPage(pf,page_cnt);
		if(arena == NULL){	
			return NULL; /*申请失败 则返回NULL*/
		}
		memset(arena,0,page_cnt*PG_SIZE);
		arena -> desc = NULL;
		arena -> cnt = page_cnt;
		arena -> large = true;
		return (void*)(arena+1);
	}else{  /*申请数量小于1024B*/
		uint8_t desc_index; /*描述符索引*/
		while(size > descs[desc_index].block_size) desc_index++;
		if(list_empty(&descs[desc_index].free_list)){ /*内存块描述符空闲内存块队列不为空*/
			arena = mallocPage(pf,1); 				  //申请新4KB内存
			if(arena == NULL) {       				  //内存不足 直接返回
				return NULL;
			}
			memset(arena,0,PG_SIZE);
			arena -> large = false;
			arena -> desc = &descs[desc_index];
			arena -> cnt = descs[desc_index].blocks_per_arena;

			uint32_t block_index  = 0;
			//操作list需关中断
			enum int_status stat = closeInt();
			struct mem_block* block=NULL; //负责遍历arene，用来组织链表
			/* 设置每个area中的mem_block */
			for(block_index = 0 ; block_index < descs[desc_index].blocks_per_arena;block_index++){
				block = arena2block(arena,block_index);
				ASSERT(find_elem(&arena->desc->free_list,&block->free_elem)==false);
				list_append(&(arena->desc->free_list),&(block->free_elem)); /*添加内存块到内存空闲队列中*/
			} 
			setIntStatus(stat);
		}
		struct mem_block* block = NULL;
		struct list_elem* pnode = list_pop(&(descs[desc_index].free_list)); 
		block = (struct mem_block*)((uint32_t)pnode-offset(struct mem_block,free_elem));
		arena=block2arena(block);
		arena -> cnt --;
		memset(block,0,descs[desc_index].block_size);
		return (void*)(block);
	}
}
```

### sys_free

free系统调用陷入函数

```c
void sys_free(void*vaddr)
{
	struct task_struct* pcb = getpcb();
	enum pool_flags pf = pcb->pgdir_vaddr==NULL?PF_KERNEL:PF_USER; /*获取当前用户身份*/
	struct mem_block* mem_block = (struct mem_block*)vaddr;
	struct arena* arena =  block2arena(mem_block);
	ASSERT(arena->large == 0 || arena->large == 1);
	if(arena->large == true){ /*若为大块内存申请释放*/
		mfree(pf,arena,arena->cnt); /*直接释放*/
	}else{ /*小块内存申请释放*/
		enum int_status stat = closeInt();
		ASSERT(find_elem(&arena->desc->free_list,(struct list_elem*)mem_block)==false);
		list_append(&arena->desc->free_list,(struct list_elem*)mem_block); /*将mem_block 重新加入到 内存描述符的空闲队列中*/
		setIntStatus(stat);
		arena->cnt++ ;
		if(arena->cnt == arena->desc->blocks_per_arena){ /*若arena中所有内存块都在等待队列中（整页空闲），则从等待队列中删除所有mem_block节点，并清楚页表项*/
			uint32_t i = 0;
			for(i=0;i<arena->cnt;i++){ /*遍历删除所有内存节点*/
				struct mem_block* block = arena2block(arena,i); 
				stat = closeInt();
				ASSERT(find_elem(&arena->desc->free_list,(struct list_elem*)block)==true);
				list_remove((struct list_elem*)block); /*删除块节点*/
				setIntStatus(stat);
			}
			mfree(pf,vaddr,1); /*清楚页表项，恢复内存位图*/
		}
	}
}
```

